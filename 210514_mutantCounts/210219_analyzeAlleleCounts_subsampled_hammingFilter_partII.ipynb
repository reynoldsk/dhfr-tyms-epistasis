{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamming-distance based error correction of mutant counts \n",
    "\n",
    "##### Adapted from JM_hamming_analysis by Thuy N. Nguyen on 191118\n",
    "\n",
    "**Edited on 200928 for processing HiSeq data from 200914.**\n",
    "**Edited on 210211 for processing subsampled Replicate 1 HiSeq data**\n",
    "**Edited on 210219 for processing subsampled Q33S TYMS Hiseq data**\n",
    "\n",
    "Purpose: To take mutant counts measured by NGS and correct these counts according to expected error of sequencing a pair of codons that are likely to be mis-assigned as another. TNN is revising JM's code to be more brief and less constrained to the parameters of the experiment. \n",
    "\n",
    "Some assumptions:\n",
    "- The mutants sequenced are from a saturation mutagenesis generated by mutating each codon to all possible amino acids by mutageneic NNS primer using inverse PCR. \n",
    "- The FASTQ files returned from NGS are processed to merge overlapping paired-end reads using a program like USEARCH or FLASh. \n",
    "- These FASTQ files containing merged paired-end reads have been processed by CountingAlleles.py, which filters each read using a Quality Score threshold of 20 (1/100 error rate) and counts all mutants in the FASTQ file. This script will also count mutants that are in this FASTQ file. \n",
    "- The output of CountingAllles.py is a tab-delimited file containing the identity of the mutant and counts of a mutant codon. EX: '1ATG\\t200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import generic_dna\n",
    "from scipy import stats #as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_seq(seq):\n",
    "    #for going from nucleotides to aa\n",
    "    seq = Seq(seq,generic_dna)\n",
    "    seq_translate = str(seq.translate().strip())\n",
    "    return seq_translate\n",
    "\n",
    "def aa2codon(aminoAcidPosition,aaPositionList,wtAAsequence,wtDNASequence):\n",
    "    #for a given amino acid position, this function will return the WT codon sequence \n",
    "    #See example above for how this function works if you need a clearer explanation\n",
    "    \n",
    "    aaPIX = list(aaPositionList).index(aminoAcidPosition)\n",
    "\n",
    "    c1 = aaPIX*3 #codon positions in the WT DNA sequence\n",
    "    c3 = c1+3\n",
    "    \n",
    "    WTcodon = wtDNASequence[c1:c3]\n",
    "    #print(translate_seq(WTcodon))\n",
    "    if translate_seq(WTcodon) == wtAAsequence[aaPIX]:\n",
    "        return WTcodon\n",
    "    else:\n",
    "        return 'error'\n",
    "\n",
    "def hammingDistance(ham_calc_wt,ham_calc_compare):\n",
    "    ham_dist = 3\n",
    "    for i in range(0, 3):\n",
    "        if ham_calc_wt[i] == ham_calc_compare[i]:\n",
    "            ham_dist = np.subtract(ham_dist, 1)\n",
    "        else:\n",
    "            continue\n",
    "    return(ham_dist)\n",
    "\n",
    "def hammingCalc(codon1,codon2,mutCount,hamming_value = -3.0 ): # hamming value is: Q-score/-10 = 30/-10 = -3\n",
    "    hammingCountError = 0\n",
    "    if codon1 != codon2:\n",
    "        ham_dist = hammingDistance(codon1,codon2)\n",
    "        hammingCountError = (mutCount*(np.power(np.power(10,hamming_value),ham_dist)))\n",
    "    else: \n",
    "        hammingCountError = 0 #identical codons will not have this hamming problem \n",
    "        \n",
    "    return hammingCountError "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables \n",
    "- path of your file of mutant counts\n",
    "\n",
    "- WT sequence of your protein of interest (both DNA and amino acid)\n",
    "- Dictionary that will be filled with your raw mutant counts\n",
    "- Dictionary that will be filled with your corrected mutant counts\n",
    "\n",
    "### Define paths for each sample and corresponding sample names.\n",
    "- The data will be organized in a dictionary and will be keyed by this sample name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subsampled_allele_counts/countingAllelesOut_1nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_2nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_3nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_4nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_5nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_6nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_7nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_8nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_9nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_10nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_11nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_12nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_13nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_14nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_15nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_16nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_17nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_18nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_19nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_20nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_21nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_22nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_23nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_24nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_25nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_26nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_27nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_28nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_29nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_30nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_31nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_32nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_33nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_34nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_35nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_36nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_37nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_38nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_39nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_40nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_41nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_42nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_43nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_44nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_45nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_46nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_47nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_48nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_49nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_50nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_51nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_52nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_53nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_54nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_55nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_56nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_57nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_58nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_59nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_60nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_61nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_62nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_63nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_64nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_65nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_66nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_67nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_68nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_69nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_70nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_71nuc.txt',\n",
       " 'subsampled_allele_counts/countingAllelesOut_72nuc.txt']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'subsampled_allele_counts/'\n",
    "\n",
    "outname = [i for i in range(1,73)]\n",
    "pathMutCounts = []\n",
    "\n",
    "for f in outname: \n",
    "    pathMutCounts.append(path+'countingAllelesOut_%snuc.txt'% f)\n",
    "\n",
    "pathMutCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to build my list of all 64 codons. These are the amino acids in alphebetical order. \n",
    "# What are all possible codons that you can be mutated to? \n",
    "\n",
    "codon_list = ['GCT', 'GCC', 'GCA', 'GCG', 'CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG', 'AAT', 'AAC', 'GAT', 'GAC', 'TGT', 'TGC'\\\n",
    ", 'CAA', 'CAG', 'GAA', 'GAG', 'GGT', 'GGC', 'GGA', 'GGG', 'CAT', 'CAC', 'ATT', 'ATC', 'ATA'\\\n",
    ", 'CTT', 'CTC', 'CTA', 'CTG', 'TTA', 'TTG', 'AAA', 'AAG', 'ATG', 'TTT', 'TTC', 'CCT', 'CCC', 'CCA', 'CCG'\\\n",
    ", 'TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC', 'ACT', 'ACC', 'ACA', 'ACG', 'TGG', 'TAT', 'TAC'\\\n",
    ", 'GTT', 'GTC', 'GTA', 'GTG', 'TAA', 'TAG', 'TGA']\n",
    "\n",
    "\n",
    "# All possible amino acids that you can be mutated to\n",
    "AA = 'ACDEFGHIKLMNPQRSTVWY*' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all possible amino acids mutants in DHFR, organized by sub-library \n",
    "sublibraries = ['SL1','SL2','SL3','SL4']\n",
    "\n",
    "conditions = np.arange(1,27) #later initialize with actual sample IDs\n",
    "\n",
    "seq_wt_aa = {}\n",
    "seq_wt_aa['full'] = 'MISLIAALAVDRVIGMENAMPWNLPADLAWFKRNTLNKPVIMGRHTWESIGRPLPGRKNIILSSQPGTDDRVTWVKSVDEAIAACGDVPEIMVIGGGRVYEQFLPKAQKLYLTHIDAEVEGDTHFPDYEPDDWESVFSEFHDADAQNSHSYCFEILERR*'\n",
    "seq_wt_aa['SL1']= 'MISLIAALAVDRVIGMENAMPWNLPADLAWFKRNTLNKPV'\n",
    "seq_wt_aa['SL2']= 'IMGRHTWESIGRPLPGRKNIILSSQPGTDDRVTWVKSVDE'\n",
    "seq_wt_aa['SL3']= 'AIAACGDVPEIMVIGGGRVYEQFLPKAQKLYLTHIDAEVE'\n",
    "seq_wt_aa['SL4']= 'GDTHFPDYEPDDWESVFSEFHDADAQNSHSYCFEILERR*'\n",
    "\n",
    "# Python index of amino acid position in DHFR \n",
    "aa_pos = {}\n",
    "aa_pos['full'] = np.arange(1,160+1)\n",
    "aa_pos['SL1'] = np.arange(1,40+1)  \n",
    "aa_pos['SL2'] = np.arange(41,80+1)\n",
    "aa_pos['SL3'] = np.arange(81,120+1)\n",
    "aa_pos['SL4'] = np.arange(121,160+1)\n",
    "\n",
    "\n",
    "# Do the same for DNA sequence\n",
    "dna_pos = {}\n",
    "for sl in sublibraries:\n",
    "    dna_pos[sl] = []\n",
    "    for aix in aa_pos[sl]:\n",
    "        codon1 = aix*3-2\n",
    "        codon2 = aix*3-1\n",
    "        codon3 = aix*3\n",
    "        dna_pos[sl].append(codon1)\n",
    "        dna_pos[sl].append(codon2)\n",
    "        dna_pos[sl].append(codon3)\n",
    "        \n",
    "seq_wt_dna = {}\n",
    "seq_wt_dna['full'] = 'ATGATCAGTCTGATTGCGGCGTTAGCGGTAGATCGCGTTATCGGCATGGAAAACGCCATGCCGTGGAACCTGCCTGCCGATCTCGCCTGGTTTAAACGCAACACCTTAAATAAACCCGTGATTATGGGCCGCCATACCTGGGAATCAATCGGTCGTCCGTTGCCAGGACGCAAAAATATTATCCTCAGCAGTCAACCGGGTACGGACGATCGCGTAACGTGGGTGAAGTCGGTGGATGAAGCCATCGCGGCGTGTGGTGACGTACCAGAAATCATGGTGATTGGCGGCGGTCGCGTTTATGAACAGTTCTTGCCAAAAGCGCAAAAACTGTATCTGACGCATATCGACGCAGAAGTGGAAGGCGACACCCATTTCCCGGATTACGAGCCGGATGACTGGGAATCGGTATTCAGCGAATTCCACGATGCTGATGCGCAGAACTCTCACAGCTATTGCTTTGAGATTCTGGAGCGGCGGTAA'\n",
    "for sl in sublibraries:\n",
    "    seq_wt_dna[sl] = seq_wt_dna['full'][dna_pos[sl][0]-1:dna_pos[sl][-1]]\n",
    "\n",
    "#check to see if DNA sequences for each SL is defined accurately \n",
    "tmp = seq_wt_dna['SL1'] + seq_wt_dna['SL2'] + seq_wt_dna['SL3'] + seq_wt_dna['SL4']\n",
    "for aix, a in enumerate(tmp): \n",
    "    if a != seq_wt_dna['full'][aix]:\n",
    "        #print aix, a, seq_wt_dna['full'][aix] #this will spit out mis-matched amino acid positions \n",
    "        print('incorrect DNA sequence')\n",
    "for sl in sublibraries:\n",
    "    if seq_wt_aa[sl] != translate_seq(seq_wt_dna[sl]):\n",
    "        print('incorrect amino acid sequence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import mutant counts in each sample and organize into a dictionary that is structured like this: \n",
    "   \n",
    "   * the structure of the data is sorted entirely into data_dict\n",
    "   \n",
    "            >> data_dict[name of sample][SL1 or SL2][Mut] = mutant count\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing each sample and storing the data in the form of a dictionary\n",
    "\n",
    "data_dict = {}\n",
    "#import the counts\n",
    "for sampleNameix, sampleName in enumerate(outname):\n",
    "    file = open(pathMutCounts[sampleNameix],'r')\n",
    "    data = file.readlines()\n",
    "    \n",
    "    data_dict[sampleName] = {}\n",
    "    for line in data:\n",
    "        \n",
    "        sp_line = line.split('\\t') \n",
    "        if sp_line[0][0:2] != 'sl':\n",
    "            continue #skip over statistics in this file \n",
    "        \n",
    "        else: \n",
    "            sl_id = sp_line[0].upper() #define sublibrary,\n",
    "            mut = sp_line[1] # mutant name\n",
    "            mut_count = float(sp_line[2].strip()) # and mutant count\n",
    "            \n",
    "            if sl_id not in data_dict[sampleName].keys():\n",
    "                \n",
    "                data_dict[sampleName][sl_id] = {}\n",
    "\n",
    "            data_dict[sampleName][sl_id][mut] = mut_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is to build matrix of all counts. \n",
    "#full_codon_matrix is the size, codon_list is the nucelotide list\n",
    "nucleotide_matrix = {}\n",
    "for condition in list(data_dict.keys()):\n",
    "    reads_mat = np.zeros(shape = (len(aa_pos['full']),len(codon_list)))\n",
    "    for slix,sl in enumerate(sublibraries):\n",
    "        if sl in data_dict[condition].keys():\n",
    "            for ipos, pos in enumerate(aa_pos[sl]):\n",
    "                for icodon, codon in enumerate(codon_list):\n",
    "                    wtCodon = aa2codon(pos,aa_pos[sl],seq_wt_aa[sl],seq_wt_dna[sl])\n",
    "                    if codon[-1] == 'A':\n",
    "                        continue\n",
    "                    if codon[-1] == 'T':\n",
    "                        continue\n",
    "                    if wtCodon != codon:\n",
    "                        mutCodon = str(pos)+codon\n",
    "                        if mutCodon in data_dict[condition][sl].keys():\n",
    "                            reads_mat[pos-1,icodon] = data_dict[condition][sl][mutCodon]\n",
    "        nucleotide_matrix[condition] = reads_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of your hamming filter here: \n",
    "\n",
    "#first, initialize dictionary with WT raw reads. As the thing iterates through each codon, \n",
    "#it will subtract error reads \n",
    "wtRawCounts = {}\n",
    "wtHammingCounts = {} #also initialize a dictionray that will store your hamming WT reads that are error\n",
    "wtHammingCorrected = {}\n",
    "for cond in outname:\n",
    "    wtRawCounts[cond] = {}\n",
    "    wtHammingCounts[cond] = {} #also initialize a dictionray that will store your hamming WT reads that are error\n",
    "    wtHammingCorrected[cond] = {}\n",
    "\n",
    "    for slix, sl in enumerate(sublibraries):\n",
    "        if sl in data_dict[cond].keys():\n",
    "            wtRawCounts[cond][sl] = data_dict[cond][sl]['WT']\n",
    "            wtHammingCounts[cond][sl] = 0\n",
    "            wtHammingCorrected[cond][sl] = 0\n",
    "\n",
    "for cond in outname: #37 of em. \n",
    "    for slix, sl in enumerate(sublibraries):\n",
    "        if sl in data_dict[cond].keys():\n",
    "            wtHammingCounts[cond][sl] = 0\n",
    "            \n",
    "            for ix, ipos in enumerate(aa_pos[sl]):\n",
    "                for jx, refCodon in enumerate(codon_list):\n",
    "                    wtCodon = aa2codon(ipos, aa_pos[sl],seq_wt_aa[sl],seq_wt_dna[sl])\n",
    "                    if wtCodon == refCodon:\n",
    "                        hammingCount = 0\n",
    "                        \n",
    "                        for kx, queryCodon in enumerate(codon_list):\n",
    "                            nMut = nucleotide_matrix[cond][ipos-1,kx]\n",
    "                            tmpHamCount = hammingCalc(refCodon,queryCodon,nMut)\n",
    "                            hammingCount+=tmpHamCount\n",
    "                        wtHammingCounts[cond][sl] = wtHammingCounts[cond][sl] + hammingCount\n",
    "\n",
    "            #determine WT reads in each sub-library are due to hamming distance error. \n",
    "            wtHammingCorrected[cond][sl] = wtRawCounts[cond][sl] - wtHammingCounts[cond][sl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutHammingCount = {}\n",
    "for condition in outname:\n",
    "    mutHammingCount[condition] = np.zeros(shape = (len(aa_pos['full']),len(codon_list)))\n",
    "    for ipos, pos in enumerate(aa_pos['full']):\n",
    "        for jx, refCodon in enumerate(codon_list):\n",
    "            hammingCounts = 0\n",
    "            for kx, queryCodon in enumerate(codon_list):\n",
    "                queryCodonMutCounts = nucleotide_matrix[condition][ipos,kx]\n",
    "                tmpHamCount = hammingCalc(refCodon,queryCodon,queryCodonMutCounts)\n",
    "                hammingCounts =+ tmpHamCount\n",
    "            mutHammingCount[condition][ipos,jx] = hammingCounts\n",
    "\n",
    "mutHammingCorrected= {}\n",
    "for condition in outname:\n",
    "    mutHammingCorrected[condition] = np.zeros(shape = (len(aa_pos['full']),len(codon_list)))\n",
    "    for ipos, pos in enumerate(aa_pos['full']):\n",
    "        for jx, refCodon in enumerate(codon_list):\n",
    "            diff = nucleotide_matrix[condition][ipos,jx] - mutHammingCount[condition][ipos,jx]\n",
    "            if diff <0:\n",
    "                mutHammingCorrected[condition][ipos,jx] = 0\n",
    "            else:\n",
    "                mutHammingCorrected[condition][ipos,jx] = diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AMINO ACID MUTANT COUNTS #This needs to be done in separately after you have corrected DNA codon reads\n",
    "\n",
    "#later loop through each condition\n",
    "aa_countsTN = {}\n",
    "for cond in outname:\n",
    "    aa_countsTN[cond] = {}\n",
    "    for sl in sublibraries:\n",
    "        aa_countsTN[cond][sl] = {}\n",
    "\n",
    "        for ipos, pos in enumerate(aa_pos[sl]):\n",
    "            for icodon, codon in enumerate(codon_list):\n",
    "                if seq_wt_aa[sl][ipos] == translate_seq(codon):\n",
    "                    continue #skip WT\n",
    "                else:\n",
    "                    mutCount = mutHammingCorrected[cond][pos-1,icodon]\n",
    "                    mutCodon = seq_wt_aa[sl][ipos]+str(pos)+translate_seq(codon)\n",
    "\n",
    "                    if mutCodon in aa_countsTN[cond][sl].keys():\n",
    "                        aa_countsTN[cond][sl][mutCodon] += mutCount\n",
    "                    else: \n",
    "                        aa_countsTN[cond][sl][mutCodon] = mutCount\n",
    "\n",
    "    for sl in sublibraries: #add WT\n",
    "        if sl in wtHammingCorrected[cond].keys():\n",
    "            aa_countsTN[cond][sl]['WT'] = wtHammingCorrected[cond][sl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in outname:\n",
    "    output_file= open('hamOut/'+str(cond)+'.txt','w') #iterate through each condition later. \n",
    "    for sl in aa_countsTN[cond].keys():\n",
    "        for m in aa_countsTN[cond][sl]:\n",
    "            mCounts = str(aa_countsTN[cond][sl][m])\n",
    "            output_file.write(sl+'\\t'+m+'\\t'+mCounts+'\\n')\n",
    "    output_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
